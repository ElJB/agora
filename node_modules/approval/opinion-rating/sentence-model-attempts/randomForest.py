# -*- coding: latin1 -*-

import psycopg2
from sklearn.ensemble import RandomForestClassifier
from sklearn.cross_validation import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
from operator import itemgetter
import re

conn = psycopg2.connect("dbname=boniface user=boniface password=blabla")

cur = conn.cursor()

cur.execute("SELECT lemma_sentence, relevance, sentiment, information FROM corpus WHERE information IS NOT NULL AND lemma_sentence IS NOT NULL")

stopWords = []

def classificationError(b, a):
	assert len(a) == len(b)
	result = {}
	for i in range(len(a)):
		key = str(a[i]) + " => " + str(b[i])
		if key not in result : result[key] = 1
		else : result[key] += 1
	return result


valueMap = {
	'useless': 1,
	'positive': 2,
	'negative': 3
}

rows = cur.fetchall()
sentences = [row[0] for row in rows]
with open("lexicon_positive.txt", "r") as p:
	positive = p.read().split('\n')
with open("lexicon_negative.txt", "r") as n:
	negative = n.read().split('\n')


for word in positive:
	sentences = map(lambda x: x.replace(" " + word + " ", " _POSITIVE "), sentences)

for word in negative:
	sentences = map(lambda x: x.replace(" " + word + " ", " _NEGATIVE "), sentences)


sentences = np.array(sentences)
information = np.array([row[3] for row in rows])
del rows

folds = StratifiedKFold(information, n_folds=3)

result = []


for train, test in folds:
	data_train = sentences[train]
	result_train = information[train]

	data_test = sentences[test]
	result_test = information[test]

	vectorizer = TfidfVectorizer(max_df=0.95, norm=False, binary=True, stop_words=stopWords)
	classifier = RandomForestClassifier(n_estimators=30, max_depth=30, min_samples_split=4)

	data_train = vectorizer.fit_transform(data_train)
	data_test = vectorizer.transform(data_test)

	classifier.fit(data_train.toarray(), result_train) 
	print [x[1] for x in sorted(zip(classifier.feature_importances_, vectorizer.get_feature_names()), key=itemgetter(0), reverse=True)[0:5]]

	print classificationError(classifier.predict(data_test.toarray()), result_test)
	result.append(classifier.score(data_test.toarray(), result_test))

print reduce(lambda x, y: x + y, result) / float(len(result))
