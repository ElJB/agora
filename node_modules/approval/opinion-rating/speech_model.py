# -*- coding: latin1 -*-

import psycopg2
from sklearn.naive_bayes import MultinomialNB
from sklearn.cross_validation import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import re
from rabbitmq_rpc import RpcClient
from subprocess import Popen
from operator import itemgetter

alpage_server = Popen(["node", "../../alpage-connector/rpcCall.js"])
alpage_client = RpcClient('alpage')

conn = psycopg2.connect("dbname=boniface user=boniface password=blabla")

cur = conn.cursor()

cur.execute("SELECT speech, rating FROM speech WHERE rating IS NOT NULL AND debate_section = $$discussions$$")

def classificationError(b, a):
	assert len(a) == len(b)
	result = {}
	for i in range(len(a)):
		key = str(a[i]) + " => " + str(b[i])
		if key not in result : result[key] = 1
		else : result[key] += 1
	return result


			

rows = cur.fetchall()
speeches = [row[0] for row in rows]
ratings = np.array([row[1] for row in rows])
del rows

# Select paragraph - First an last paragraph
speeches = map(lambda y: y[0] + " " + y[-1], map(lambda x: x.split("\n\n"), speeches))

# text to sentences
sentenceRe = re.compile("[ABCDEFGHIJKLMNOPQRSTUVWXYZ][^\.?!]+[^ABCDEFGHIJKLMNOPQRSTUVWXYZ][\.?!]")
speeches = map(lambda x: sentenceRe.findall(x), speeches)

# sentences to lemma
speeches = map(lambda x: map(lambda y: alpage_client.call(y), x), speeches)
speeches = np.array(map(lambda x: reduce(lambda y, z: y + " " + z, x, ""), speeches))

# take into accout negations
speeches = map(lambda x: negate(x), speeches)


folds = StratifiedKFold(ratings, n_folds=3)

result = []

for train, test in folds:
	data_train = speeches[train]
	result_train = ratings[train]

	data_test = speeches[test]
	result_test = ratings[test]

	classifier = MultinomialNB()
	vectorizer = TfidfVectorizer()

	data_train = vectorizer.fit_transform(data_train).toarray()
	data_test = vectorizer.transform(data_test).toarray()

	classifier.fit(data_train, result_train)
	print [x[1] for x in sorted(zip(classifier.feature_importances_, vectorizer.get_feature_names()), key=itemgetter(0), reverse=True)[0:5]]

	print classificationError(classifier.predict(data_test), result_test)
	result.append(classifier.score(data_test, result_test))

print reduce(lambda x, y: x + y, result) / float(len(result))
